{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d5e8ebd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e55dfcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisicong/miniforge3/envs/transformer/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3579: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "/Users/lisicong/miniforge3/envs/transformer/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:1896: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n",
      "/Users/lisicong/miniforge3/envs/transformer/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:1909: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo-0125 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Data model\n",
    "class RouteQuery(BaseModel):\n",
    "    \"\"\"Route a user query to the most relevant datasource.\"\"\"\n",
    "\n",
    "    datasource: Literal[\"python_docs\", \"js_docs\", \"golang_docs\"] = Field(\n",
    "        ...,\n",
    "        description=\"Given a user question choose which datasource would be most relevant for answering their question\",\n",
    "    )\n",
    "\n",
    "# LLM with function call \n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "structured_llm = llm.with_structured_output(RouteQuery)\n",
    "\n",
    "# Prompt \n",
    "system = \"\"\"You are an expert at routing a user question to the appropriate data source.\n",
    "\n",
    "Based on the programming language the question is referring to, route it to the relevant data source.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define router \n",
    "router = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dce48f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"\"\"Why doesn't the following code work:\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\"human\", \"speak in {language}\"])\n",
    "prompt.invoke(\"french\")\n",
    "\"\"\"\n",
    "\n",
    "result = router.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18a90884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python_docs'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.datasource"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e5d78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_route(result):\n",
    "    if \"python_docs\" in result.datasource.lower():\n",
    "        ### Logic here \n",
    "        return \"chain for python_docs\"\n",
    "    elif \"js_docs\" in result.datasource.lower():\n",
    "        ### Logic here \n",
    "        return \"chain for js_docs\"\n",
    "    else:\n",
    "        ### Logic here \n",
    "        return \"golang_docs\"\n",
    "\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "full_chain = router | RunnableLambda(choose_route)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bc62d2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chain for python_docs'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f20cd84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PHYSICS\n",
      "A black hole is a region in space where gravity is so strong that nothing, not even light, can escape from it. Black holes are formed when massive stars collapse under their own gravity. They have a singularity at their center, which is a point of infinite density and gravity. The boundary surrounding a black hole is called the event horizon.\n"
     ]
    }
   ],
   "source": [
    "from langchain.utils.math import cosine_similarity\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "\n",
    "# Two prompts\n",
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. You are great at answering math questions. \\\n",
    "You are so good because you are able to break down hard problems into their component parts, \\\n",
    "answer the component parts, and then put them together to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{query}\"\"\"\n",
    "\n",
    "# Embed prompts\n",
    "embeddings = OpenAIEmbeddings()\n",
    "prompt_templates = [physics_template, math_template]\n",
    "prompt_embeddings = embeddings.embed_documents(prompt_templates)\n",
    "\n",
    "# Route question to prompt \n",
    "def prompt_router(input):\n",
    "    # Embed question\n",
    "    query_embedding = embeddings.embed_query(input[\"query\"])\n",
    "    # Compute similarity\n",
    "    similarity = cosine_similarity([query_embedding], prompt_embeddings)[0]\n",
    "    most_similar = prompt_templates[similarity.argmax()]\n",
    "    # Chosen prompt \n",
    "    print(\"Using MATH\" if most_similar == math_template else \"Using PHYSICS\")\n",
    "    return PromptTemplate.from_template(most_similar)\n",
    "\n",
    "\n",
    "chain = (\n",
    "    {\"query\": RunnablePassthrough()}\n",
    "    | RunnableLambda(prompt_router)\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "print(chain.invoke(\"What's a black hole\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a62892",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39aa28fb",
   "metadata": {},
   "source": [
    "## Query structuring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd9a0442",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 因为YoutubeLoader本地用不了（暂时不清楚原因）\n",
    "\n",
    "import requests\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "class BilibiliLoader:\n",
    "    def __init__(self, url: str, add_video_info: bool = True):\n",
    "        self.url = url\n",
    "        self.add_video_info = add_video_info\n",
    "        self.metadata = {}\n",
    "\n",
    "    def _get_video_info(self):\n",
    "        \"\"\"使用 yt-dlp 获取 Bilibili 视频信息\"\"\"\n",
    "        import yt_dlp\n",
    "\n",
    "        ydl_opts = {\n",
    "            'quiet': True,\n",
    "            'skip_download': True,\n",
    "            # 可添加 cookie 文件应对登录墙\n",
    "            # 'cookiefile': 'cookies.txt',\n",
    "        }\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            info = ydl.extract_info(self.url, download=False)\n",
    "            return {\n",
    "                \"title\": info.get(\"title\"),\n",
    "                \"description\": info.get(\"description\"),\n",
    "                \"author\": info.get(\"uploader\"),\n",
    "                \"upload_date\": info.get(\"upload_date\"),\n",
    "                \"duration\": info.get(\"duration\"),  # 秒\n",
    "                \"view_count\": info.get(\"view_count\"),\n",
    "                \"thumbnail\": info.get(\"thumbnail\"),\n",
    "                \"webpage_url\": info.get(\"webpage_url\"),\n",
    "            }\n",
    "\n",
    "    def _get_subtitles(self):\n",
    "        \"\"\"获取字幕（如果存在）\"\"\"\n",
    "        import yt_dlp\n",
    "\n",
    "        ydl_opts = {\n",
    "            'writesubtitles': True,\n",
    "            'writeautomaticsub': True,  # 自动字幕\n",
    "            'subtitleslangs': ['zh'],   # 中文\n",
    "            'skip_download': False,\n",
    "            'quiet': True,\n",
    "        }\n",
    "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "            result = ydl.extract_info(self.url, download=False)\n",
    "            subtitles = result.get('subtitles') or result.get('automatic_captions')\n",
    "            if not subtitles:\n",
    "                return None\n",
    "\n",
    "            # 提取中文字幕文本（自动字幕优先）\n",
    "            for lang in ['zh', 'zh-Hans', 'zh-CN']:\n",
    "                if lang in subtitles and subtitles[lang]:\n",
    "                    text = \"\"\n",
    "                    for line in subtitles[lang]:\n",
    "                        if line.get('ext') == 'ass':\n",
    "                            continue\n",
    "                        text += line.get('text', '') + \"\\n\"\n",
    "                    return text.strip()\n",
    "\n",
    "            # 尝试英文或其他\n",
    "            for sub in subtitles.values():\n",
    "                if sub:\n",
    "                    text = \"\"\n",
    "                    for line in sub:\n",
    "                        text += line.get('text', '') + \"\\n\"\n",
    "                    return text.strip()\n",
    "\n",
    "        return None\n",
    "\n",
    "    def load(self):\n",
    "        \"\"\"模拟 langchain 的 load() 方法\"\"\"\n",
    "        if self.add_video_info:\n",
    "            self.metadata = self._get_video_info()\n",
    "\n",
    "        subtitle_text = self._get_subtitles()\n",
    "        if not subtitle_text:\n",
    "            subtitle_text = \"(No subtitle available)\"\n",
    "\n",
    "        doc = Document(\n",
    "            page_content=subtitle_text,\n",
    "            metadata=self.metadata\n",
    "        )\n",
    "        return [doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1cbd2d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: [BiliBili] Subtitles are only available when logged in. Use --cookies-from-browser or --cookies for the authentication. See  https://github.com/yt-dlp/yt-dlp/wiki/FAQ#how-do-i-pass-cookies-to-yt-dlp  for how to manually pass cookies\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'title': '终于知道Transformer 为啥离不开 RoPE了', 'description': '为什么 Transformer 需要位置编码？为什么正弦嵌入不够用？RoPE 又是如何通过“旋转”解决长文本记忆的问题？这一期我会彻底讲清 RoPE 的设计思路。看完你会明白，RoPE 不只是一个小改动，而是让大模型真正具备长序列理解能力的关键。', 'author': '机器学习算法应用实战', 'upload_date': '20250820', 'duration': 364.042, 'view_count': 7005, 'thumbnail': 'http://i2.hdslb.com/bfs/archive/bace2a7bba801c6262d63ce69b74e39b65e63f53.jpg', 'webpage_url': 'https://www.bilibili.com/video/BV166egzvE9H/'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import YoutubeLoader\n",
    "\n",
    "# docs = YoutubeLoader.from_youtube_url(\n",
    "#     \"https://www.youtube.com/watch?v=pbAd8O1Lvm4\", add_video_info=True\n",
    "# ).load()\n",
    "\n",
    "# docs[0].metadata\n",
    "\n",
    "loader = BilibiliLoader(\"https://www.bilibili.com/video/BV166egzvE9H/\", add_video_info=True)\n",
    "docs = loader.load()\n",
    "\n",
    "# 输出元数据\n",
    "print(docs[0].metadata)\n",
    "\n",
    "# # 输出字幕内容\n",
    "# print(docs[0].page_content[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a00c18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisicong/miniforge3/envs/transformer/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3579: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "from typing import Literal, Optional, Tuple\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "class TutorialSearch(BaseModel):\n",
    "    \"\"\"Search over a database of tutorial videos about a software library.\"\"\"\n",
    "\n",
    "    content_search: str = Field(\n",
    "        ...,\n",
    "        description=\"Similarity search query applied to video transcripts.\",\n",
    "    )\n",
    "    title_search: str = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"Alternate version of the content search query to apply to video titles. \"\n",
    "            \"Should be succinct and only include key words that could be in a video \"\n",
    "            \"title.\"\n",
    "        ),\n",
    "    )\n",
    "    min_view_count: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Minimum view count filter, inclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "    max_view_count: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Maximum view count filter, exclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "    earliest_publish_date: Optional[datetime.date] = Field(\n",
    "        None,\n",
    "        description=\"Earliest publish date filter, inclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "    latest_publish_date: Optional[datetime.date] = Field(\n",
    "        None,\n",
    "        description=\"Latest publish date filter, exclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "    min_length_sec: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Minimum video length in seconds, inclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "    max_length_sec: Optional[int] = Field(\n",
    "        None,\n",
    "        description=\"Maximum video length in seconds, exclusive. Only use if explicitly specified.\",\n",
    "    )\n",
    "\n",
    "    def pretty_print(self) -> None:\n",
    "        for field in self.__fields__:\n",
    "            if getattr(self, field) is not None and getattr(self, field) != getattr(\n",
    "                self.__fields__[field], \"default\", None\n",
    "            ):\n",
    "                print(f\"{field}: {getattr(self, field)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9aba5327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_search: how to load documents in LangChain\n",
      "title_search: LangChain document loaders\n",
      "min_view_count: 1000\n",
      "earliest_publish_date: 2023-01-01\n",
      "max_length_sec: 1200\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "\n",
    "query = TutorialSearch(\n",
    "    content_search=\"how to load documents in LangChain\",\n",
    "    title_search=\"LangChain document loaders\",\n",
    "    min_view_count=1000,\n",
    "    earliest_publish_date=date(2023, 1, 1),\n",
    "    max_length_sec=1200  # < 20 minutes\n",
    ")\n",
    "\n",
    "query.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f719e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lisicong/miniforge3/envs/transformer/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:1896: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n",
      "/Users/lisicong/miniforge3/envs/transformer/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:1909: UserWarning: Cannot use method='json_schema' with model gpt-3.5-turbo-0125 since it doesn't support OpenAI's Structured Output API. You can see supported models here: https://platform.openai.com/docs/guides/structured-outputs#supported-models. To fix this warning, set `method='function_calling'. Overriding to method='function_calling'.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "system = \"\"\"You are an expert at converting user questions into database queries. \\\n",
    "You have access to a database of tutorial videos about a software library for building LLM-powered applications. \\\n",
    "Given a question, return a database query optimized to retrieve the most relevant results.\n",
    "\n",
    "If there are acronyms or words you are not familiar with, do not try to rephrase them.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)\n",
    "# 做functin call\n",
    "structured_llm = llm.with_structured_output(TutorialSearch)\n",
    "query_analyzer = prompt | structured_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03be54b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_search: rag from scratch\n",
      "title_search: rag from scratch\n"
     ]
    }
   ],
   "source": [
    "query_analyzer.invoke({\"question\": \"rag from scratch\"}).pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b91ba689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_search: chat langchain\n",
      "title_search: chat langchain\n",
      "earliest_publish_date: 2023-01-01\n",
      "latest_publish_date: 2024-01-01\n"
     ]
    }
   ],
   "source": [
    "query_analyzer.invoke(\n",
    "    {\"question\": \"videos on chat langchain published in 2023\"}\n",
    ").pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbb84e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content_search: chat langchain\n",
      "title_search: chat langchain\n",
      "earliest_publish_date: 2024-01-01\n"
     ]
    }
   ],
   "source": [
    "query_analyzer.invoke(\n",
    "    {\"question\": \"videos that are focused on the topic of chat langchain that are published before 2024\"}\n",
    ").pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
