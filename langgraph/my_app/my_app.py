import os
from dotenv import load_dotenv 
from langchain_deepseek import ChatDeepSeek
from langgraph.prebuilt import create_react_agent
from langchain_core.tools import tool
from pydantic import BaseModel, Field
import matplotlib
import json
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import pymysql
from langchain_tavily import TavilySearch
import requests
from bs4 import BeautifulSoup
import subprocess
import platform
import psutil
import datetime
from urllib.parse import quote
import time
import csv
from pathlib import Path



load_dotenv(override=True)


# âœ… åˆ›å»ºæç¤ºè¯æ¨¡æ¿
prompt = """
ä½ æ˜¯ä¸€åç»éªŒä¸°å¯Œçš„æ™ºèƒ½åŠ©æ‰‹ï¼Œæ“…é•¿å¸®åŠ©ç”¨æˆ·é«˜æ•ˆå®Œæˆå„ç§ä»»åŠ¡ã€‚ä½ æ‹¥æœ‰ä»¥ä¸‹å¼ºå¤§çš„å·¥å…·èƒ½åŠ›ï¼š

## ğŸ“ æ–‡ä»¶å’Œç³»ç»Ÿæ“ä½œå·¥å…·
1. **æ–‡ä»¶æ“ä½œ (file_operations)**: è¯»å–ã€å†™å…¥ã€è¿½åŠ ã€åˆ—å‡ºç›®å½•ã€åˆ é™¤æ–‡ä»¶ã€æ£€æŸ¥æ–‡ä»¶å­˜åœ¨æ€§
2. **ç³»ç»Ÿä¿¡æ¯ (get_system_info)**: è·å–æ“ä½œç³»ç»Ÿã€CPUã€å†…å­˜ã€ç£ç›˜ç­‰ç³»ç»Ÿä¿¡æ¯
3. **å‘½ä»¤æ‰§è¡Œ (execute_command)**: å®‰å…¨åœ°æ‰§è¡Œç³»ç»Ÿå‘½ä»¤ï¼ˆç¦æ­¢å±é™©å‘½ä»¤ï¼‰
4. **æ—¶é—´æ—¥æœŸ (datetime_operations)**: è·å–å½“å‰æ—¶é—´ã€æ ¼å¼åŒ–æ—¥æœŸã€æ—¥æœŸè®¡ç®—ç­‰
5. **CSVå¤„ç† (csv_operations)**: è¯»å–ã€å†™å…¥ã€åˆ†æCSVæ–‡ä»¶

## ğŸ’¾ æ•°æ®åº“å’Œæ•°æ®åˆ†æå·¥å…·
6. **Pythonæ‰§è¡Œ (python_inter)**: æ‰§è¡Œéç»˜å›¾ç±»Pythonä»£ç ï¼Œæ•°æ®å¤„ç†å’Œè®¡ç®—
7. **ç»˜å›¾å·¥å…· (fig_inter)**: æ‰§è¡Œmatplotlib/seabornç»˜å›¾ä»£ç å¹¶ä¿å­˜å›¾ç‰‡


## ğŸ¯ å·¥å…·ä½¿ç”¨æŒ‡å—

**æ–‡ä»¶æ“ä½œæ—¶ï¼š**
- è¯»å†™æ–‡ä»¶ â†’ ä½¿ç”¨ `file_operations`
- å¤„ç†CSVæ•°æ® â†’ ä½¿ç”¨ `csv_operations`
- ç³»ç»Ÿä¿¡æ¯æŸ¥è¯¢ â†’ ä½¿ç”¨ `get_system_info`
- æ‰§è¡Œå‘½ä»¤ â†’ ä½¿ç”¨ `execute_command`ï¼ˆå®‰å…¨é™åˆ¶ï¼‰

**æ•°æ®åˆ†ææ—¶ï¼š**
- æ•°æ®å¤„ç† â†’ ä½¿ç”¨ `python_inter`
- æ•°æ®å¯è§†åŒ– â†’ ä½¿ç”¨ `fig_inter`ï¼ˆå¿…é¡»åˆ›å»ºfigå¯¹è±¡ï¼Œä¸è¦ç”¨plt.show()ï¼‰

**æ—¶é—´å¤„ç†æ—¶ï¼š**
- è·å–å½“å‰æ—¶é—´ã€æ—¥æœŸè®¡ç®— â†’ ä½¿ç”¨ `datetime_operations`

## âš ï¸ é‡è¦æ³¨æ„äº‹é¡¹

1. **ç»˜å›¾è¦æ±‚ï¼š**
   - å¿…é¡»ä½¿ç”¨ `fig = plt.figure()` æˆ– `fig, ax = plt.subplots()` åˆ›å»ºå›¾åƒå¯¹è±¡
   - ä¸è¦ä½¿ç”¨ `plt.show()`
   - å›¾è¡¨æ ‡ç­¾å’Œæ ‡é¢˜ä½¿ç”¨è‹±æ–‡
   - è°ƒç”¨ `fig.tight_layout()`

2. **å®‰å…¨é™åˆ¶ï¼š**
   - å‘½ä»¤æ‰§è¡Œå·¥å…·ç¦æ­¢å±é™©å‘½ä»¤ï¼ˆå¦‚rm -rf, formatç­‰ï¼‰
   - æ–‡ä»¶æ“ä½œé™åˆ¶åœ¨å®‰å…¨èŒƒå›´å†…

3. **è¾“å‡ºæ ¼å¼ï¼š**
   - ä½¿ç”¨**ç®€ä½“ä¸­æ–‡**å›ç­”
   - JSONæ•°æ®è¦æå–å…³é”®ä¿¡æ¯ç®€è¦è¯´æ˜
   - ç”Ÿæˆå›¾ç‰‡æ—¶ä½¿ç”¨Markdownæ ¼å¼ï¼š`![æè¿°](images/å›¾ç‰‡å.png)`
   - ä¿æŒä¸“ä¸šã€ç®€æ´çš„é£æ ¼

4. **å·¥å…·é€‰æ‹©ä¼˜å…ˆçº§ï¼š**
   - æ–‡ä»¶å¤„ç† â†’ ä¸“ç”¨æ–‡ä»¶å·¥å…· â†’ é€šç”¨Pythonå·¥å…·

è¯·æ ¹æ®ç”¨æˆ·éœ€æ±‚é€‰æ‹©æœ€åˆé€‚çš„å·¥å…·ï¼Œæä¾›å‡†ç¡®ã€é«˜æ•ˆçš„å¸®åŠ©ã€‚
"""

# âœ… åˆ›å»ºæ–‡ä»¶æ“ä½œå·¥å…·
class FileOperationSchema(BaseModel):
    operation: str = Field(description="æ“ä½œç±»å‹: read, write, append, list, delete, exists")
    file_path: str = Field(description="æ–‡ä»¶è·¯å¾„")
    content: str = Field(default="", description="å†™å…¥çš„å†…å®¹ï¼ˆä»…ç”¨äºwriteå’Œappendæ“ä½œï¼‰")

@tool(args_schema=FileOperationSchema)
def file_operations(operation: str, file_path: str, content: str = "") -> str:
    """
    æ‰§è¡Œæ–‡ä»¶æ“ä½œï¼ŒåŒ…æ‹¬è¯»å–ã€å†™å…¥ã€è¿½åŠ ã€åˆ—å‡ºç›®å½•ã€åˆ é™¤æ–‡ä»¶ã€æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€‚
    æ”¯æŒçš„æ“ä½œç±»å‹ï¼šread, write, append, list, delete, exists
    """
    try:
        path = Path(file_path)
        
        if operation == "read":
            if path.exists() and path.is_file():
                with open(path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if len(content) > 2000:
                        content = content[:2000] + "\n\n[æ–‡ä»¶å†…å®¹å·²æˆªæ–­...]"
                    return content
            else:
                return f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                
        elif operation == "write":
            path.parent.mkdir(parents=True, exist_ok=True)
            with open(path, 'w', encoding='utf-8') as f:
                f.write(content)
            return f"âœ… æ–‡ä»¶å·²å†™å…¥: {file_path}"
            
        elif operation == "append":
            path.parent.mkdir(parents=True, exist_ok=True)
            with open(path, 'a', encoding='utf-8') as f:
                f.write(content)
            return f"âœ… å†…å®¹å·²è¿½åŠ åˆ°æ–‡ä»¶: {file_path}"
            
        elif operation == "list":
            if path.exists() and path.is_dir():
                items = []
                for item in path.iterdir():
                    item_type = "ç›®å½•" if item.is_dir() else "æ–‡ä»¶"
                    size = item.stat().st_size if item.is_file() else "-"
                    items.append(f"{item_type}: {item.name} ({size} bytes)")
                return "\n".join(items[:50])  # é™åˆ¶æ˜¾ç¤º50ä¸ªé¡¹ç›®
            else:
                return f"ç›®å½•ä¸å­˜åœ¨: {file_path}"
                
        elif operation == "delete":
            if path.exists():
                if path.is_file():
                    path.unlink()
                    return f"âœ… æ–‡ä»¶å·²åˆ é™¤: {file_path}"
                else:
                    return f"âŒ æ— æ³•åˆ é™¤ç›®å½•ï¼Œè¯·ä½¿ç”¨ä¸“é—¨çš„ç›®å½•åˆ é™¤å·¥å…·"
            else:
                return f"æ–‡ä»¶ä¸å­˜åœ¨: {file_path}"
                
        elif operation == "exists":
            return f"æ–‡ä»¶å­˜åœ¨: {path.exists()}"
            
        else:
            return f"ä¸æ”¯æŒçš„æ“ä½œç±»å‹: {operation}"
            
    except Exception as e:
        return f"æ–‡ä»¶æ“ä½œå¤±è´¥: {str(e)}"


# âœ… åˆ›å»ºç³»ç»Ÿä¿¡æ¯å·¥å…·
@tool
def get_system_info() -> str:
    """
    è·å–å½“å‰ç³»ç»Ÿçš„åŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬æ“ä½œç³»ç»Ÿã€CPUã€å†…å­˜ã€ç£ç›˜ä½¿ç”¨æƒ…å†µç­‰ã€‚
    """
    try:
        info = {
            "æ“ä½œç³»ç»Ÿ": platform.system(),
            "ç³»ç»Ÿç‰ˆæœ¬": platform.release(),
            "å¤„ç†å™¨": platform.processor(),
            "CPUæ ¸å¿ƒæ•°": psutil.cpu_count(logical=False),
            "é€»è¾‘CPUæ•°": psutil.cpu_count(logical=True),
            "CPUä½¿ç”¨ç‡": f"{psutil.cpu_percent(interval=1):.1f}%",
            "å†…å­˜æ€»é‡": f"{psutil.virtual_memory().total / (1024**3):.1f} GB",
            "å†…å­˜ä½¿ç”¨ç‡": f"{psutil.virtual_memory().percent:.1f}%",
            "ç£ç›˜ä½¿ç”¨ç‡": f"{psutil.disk_usage('/').percent:.1f}%",
            "å½“å‰æ—¶é—´": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        }
        
        return json.dumps(info, ensure_ascii=False, indent=2)
        
    except Exception as e:
        return f"è·å–ç³»ç»Ÿä¿¡æ¯å¤±è´¥: {str(e)}"
    
# âœ… åˆ›å»ºå‘½ä»¤æ‰§è¡Œå·¥å…·
class CommandSchema(BaseModel):
    command: str = Field(description="è¦æ‰§è¡Œçš„å‘½ä»¤")
    timeout: int = Field(default=30, description="è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰")


@tool(args_schema=CommandSchema)
def execute_command(command: str, timeout: int = 30) -> str:
    """
    æ‰§è¡Œç³»ç»Ÿå‘½ä»¤å¹¶è¿”å›ç»“æœã€‚
    æ³¨æ„ï¼šä»…æ‰§è¡Œå®‰å…¨çš„å‘½ä»¤ï¼Œé¿å…æ‰§è¡Œå¯èƒ½æŸå®³ç³»ç»Ÿçš„å‘½ä»¤ã€‚
    """
    try:
        # å®‰å…¨æ£€æŸ¥ï¼šç¦æ­¢æ‰§è¡Œå±é™©å‘½ä»¤
        dangerous_commands = ['rm -rf', 'del', 'format', 'fdisk', 'mkfs', 'dd if=', 'shutdown', 'reboot']
        if any(dangerous in command.lower() for dangerous in dangerous_commands):
            return "âŒ æ‹’ç»æ‰§è¡Œæ½œåœ¨å±é™©å‘½ä»¤"
        
        result = subprocess.run(
            command,
            shell=True,
            capture_output=True,
            text=True,
            timeout=timeout
        )
        
        output = result.stdout if result.stdout else result.stderr
        if len(output) > 2000:
            output = output[:2000] + "\n\n[è¾“å‡ºå·²æˆªæ–­...]"
            
        return f"å‘½ä»¤æ‰§è¡Œç»“æœ (è¿”å›ç : {result.returncode}):\n{output}"
        
    except subprocess.TimeoutExpired:
        return f"âŒ å‘½ä»¤æ‰§è¡Œè¶…æ—¶ ({timeout}ç§’)"
    except Exception as e:
        return f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {str(e)}"

# âœ… åˆ›å»ºæ—¶é—´å’Œæ—¥æœŸå·¥å…·
class DateTimeSchema(BaseModel):
    operation: str = Field(description="æ“ä½œç±»å‹: now, format, calculate, timezone")
    date_string: str = Field(default="", description="æ—¥æœŸå­—ç¬¦ä¸²ï¼ˆç”¨äºæ ¼å¼åŒ–æˆ–è®¡ç®—ï¼‰")
    format_string: str = Field(default="%Y-%m-%d %H:%M:%S", description="æ—¥æœŸæ ¼å¼")
    days_offset: int = Field(default=0, description="å¤©æ•°åç§»é‡ï¼ˆç”¨äºæ—¥æœŸè®¡ç®—ï¼‰")

@tool(args_schema=DateTimeSchema)
def datetime_operations(operation: str, date_string: str = "", format_string: str = "%Y-%m-%d %H:%M:%S", days_offset: int = 0) -> str:
    """
    æ‰§è¡Œæ—¥æœŸæ—¶é—´ç›¸å…³æ“ä½œï¼ŒåŒ…æ‹¬è·å–å½“å‰æ—¶é—´ã€æ ¼å¼åŒ–æ—¥æœŸã€æ—¥æœŸè®¡ç®—ç­‰ã€‚
    """
    try:
        if operation == "now":
            return datetime.datetime.now().strftime(format_string)
            
        elif operation == "format":
            if date_string:
                # å°è¯•è§£ææ—¥æœŸå­—ç¬¦ä¸²
                dt = datetime.datetime.fromisoformat(date_string.replace('Z', '+00:00'))
                return dt.strftime(format_string)
            else:
                return "è¯·æä¾›è¦æ ¼å¼åŒ–çš„æ—¥æœŸå­—ç¬¦ä¸²"
                
        elif operation == "calculate":
            base_date = datetime.datetime.now()
            if date_string:
                base_date = datetime.datetime.fromisoformat(date_string.replace('Z', '+00:00'))
            
            new_date = base_date + datetime.timedelta(days=days_offset)
            return new_date.strftime(format_string)
            
        elif operation == "timezone":
            import time
            return f"å½“å‰æ—¶åŒº: {time.tzname[0]}, UTCåç§»: {time.timezone // 3600} å°æ—¶"
            
        else:
            return f"ä¸æ”¯æŒçš„æ“ä½œç±»å‹: {operation}"
            
    except Exception as e:
        return f"æ—¥æœŸæ—¶é—´æ“ä½œå¤±è´¥: {str(e)}"

# âœ… åˆ›å»ºCSVæ•°æ®å¤„ç†å·¥å…·
class CSVOperationSchema(BaseModel):
    operation: str = Field(description="æ“ä½œç±»å‹: read, write, analyze")
    file_path: str = Field(description="CSVæ–‡ä»¶è·¯å¾„")
    data: str = Field(default="", description="CSVæ•°æ®ï¼ˆJSONæ ¼å¼ï¼Œç”¨äºå†™å…¥æ“ä½œï¼‰")

@tool(args_schema=CSVOperationSchema)
def csv_operations(operation: str, file_path: str, data: str = "") -> str:
    """
    æ‰§è¡ŒCSVæ–‡ä»¶æ“ä½œï¼ŒåŒ…æ‹¬è¯»å–ã€å†™å…¥ã€åŸºæœ¬åˆ†æã€‚
    """
    try:
        if operation == "read":
            df = pd.read_csv(file_path)
            # é™åˆ¶æ˜¾ç¤ºè¡Œæ•°
            if len(df) > 10:
                preview = df.head(10)
                return f"CSVæ–‡ä»¶é¢„è§ˆï¼ˆå‰10è¡Œï¼‰ï¼š\n{preview.to_string()}\n\næ€»è¡Œæ•°: {len(df)}, æ€»åˆ—æ•°: {len(df.columns)}"
            else:
                return f"CSVæ–‡ä»¶å†…å®¹ï¼š\n{df.to_string()}"
                
        elif operation == "write":
            if data:
                import json
                json_data = json.loads(data)
                df = pd.DataFrame(json_data)
                df.to_csv(file_path, index=False)
                return f"âœ… æ•°æ®å·²å†™å…¥CSVæ–‡ä»¶: {file_path}"
            else:
                return "è¯·æä¾›è¦å†™å…¥çš„æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰"
                
        elif operation == "analyze":
            df = pd.read_csv(file_path)
            analysis = {
                "è¡Œæ•°": len(df),
                "åˆ—æ•°": len(df.columns),
                "åˆ—å": list(df.columns),
                "æ•°æ®ç±»å‹": df.dtypes.to_dict(),
                "ç¼ºå¤±å€¼": df.isnull().sum().to_dict(),
                "æ•°å€¼åˆ—ç»Ÿè®¡": df.describe().to_dict() if len(df.select_dtypes(include=['number']).columns) > 0 else "æ— æ•°å€¼åˆ—"
            }
            return json.dumps(analysis, ensure_ascii=False, indent=2, default=str)
            
        else:
            return f"ä¸æ”¯æŒçš„æ“ä½œç±»å‹: {operation}"
            
    except Exception as e:
        return f"CSVæ“ä½œå¤±è´¥: {str(e)}"

# âœ…åˆ›å»ºPythonä»£ç æ‰§è¡Œå·¥å…·
# Pythonä»£ç æ‰§è¡Œå·¥å…·ç»“æ„åŒ–å‚æ•°è¯´æ˜
class PythonCodeInput(BaseModel):
    py_code: str = Field(description="ä¸€æ®µåˆæ³•çš„ Python ä»£ç å­—ç¬¦ä¸²ï¼Œä¾‹å¦‚ '2 + 2' æˆ– 'x = 3\\ny = x * 2'")


@tool(args_schema=PythonCodeInput)
def python_inter(py_code):
    """
    å½“ç”¨æˆ·éœ€è¦ç¼–å†™Pythonç¨‹åºå¹¶æ‰§è¡Œæ—¶ï¼Œè¯·è°ƒç”¨è¯¥å‡½æ•°ã€‚
    è¯¥å‡½æ•°å¯ä»¥æ‰§è¡Œä¸€æ®µPythonä»£ç å¹¶è¿”å›æœ€ç»ˆç»“æœï¼Œéœ€è¦æ³¨æ„ï¼Œæœ¬å‡½æ•°åªèƒ½æ‰§è¡Œéç»˜å›¾ç±»çš„ä»£ç ï¼Œè‹¥æ˜¯ç»˜å›¾ç›¸å…³ä»£ç ï¼Œåˆ™éœ€è¦è°ƒç”¨fig_interå‡½æ•°è¿è¡Œã€‚
    """    
    g = globals()
    try:
        # å°è¯•å¦‚æœæ˜¯è¡¨è¾¾å¼ï¼Œåˆ™è¿”å›è¡¨è¾¾å¼è¿è¡Œç»“æœ
        return str(eval(py_code, g))
    # è‹¥æŠ¥é”™ï¼Œåˆ™å…ˆæµ‹è¯•æ˜¯å¦æ˜¯å¯¹ç›¸åŒå˜é‡é‡å¤èµ‹å€¼
    except Exception as e:
        global_vars_before = set(g.keys())
        try:            
            exec(py_code, g)
        except Exception as e:
            return f"ä»£ç æ‰§è¡Œæ—¶æŠ¥é”™{e}"
        global_vars_after = set(g.keys())
        new_vars = global_vars_after - global_vars_before
        # è‹¥å­˜åœ¨æ–°å˜é‡
        if new_vars:
            result = {var: g[var] for var in new_vars}
            # print("ä»£ç å·²é¡ºåˆ©æ‰§è¡Œï¼Œæ­£åœ¨è¿›è¡Œç»“æœæ¢³ç†...")
            return str(result)
        else:
            # print("ä»£ç å·²é¡ºåˆ©æ‰§è¡Œï¼Œæ­£åœ¨è¿›è¡Œç»“æœæ¢³ç†...")
            return "å·²ç»é¡ºåˆ©æ‰§è¡Œä»£ç "

# âœ… åˆ›å»ºç»˜å›¾å·¥å…·
# ç»˜å›¾å·¥å…·ç»“æ„åŒ–å‚æ•°è¯´æ˜
class FigCodeInput(BaseModel):
    py_code: str = Field(description="è¦æ‰§è¡Œçš„ Python ç»˜å›¾ä»£ç ï¼Œå¿…é¡»ä½¿ç”¨ matplotlib/seaborn åˆ›å»ºå›¾åƒå¹¶èµ‹å€¼ç»™å˜é‡")
    fname: str = Field(description="å›¾åƒå¯¹è±¡çš„å˜é‡åï¼Œä¾‹å¦‚ 'fig'ï¼Œç”¨äºä»ä»£ç ä¸­æå–å¹¶ä¿å­˜ä¸ºå›¾ç‰‡")

@tool(args_schema=FigCodeInput)
def fig_inter(py_code: str, fname: str) -> str:
    """
    å½“ç”¨æˆ·éœ€è¦ä½¿ç”¨ Python è¿›è¡Œå¯è§†åŒ–ç»˜å›¾ä»»åŠ¡æ—¶ï¼Œè¯·è°ƒç”¨è¯¥å‡½æ•°ã€‚

    æ³¨æ„ï¼š
    1. æ‰€æœ‰ç»˜å›¾ä»£ç å¿…é¡»åˆ›å»ºä¸€ä¸ªå›¾åƒå¯¹è±¡ï¼Œå¹¶å°†å…¶èµ‹å€¼ä¸ºæŒ‡å®šå˜é‡åï¼ˆä¾‹å¦‚ `fig`ï¼‰ã€‚
    2. å¿…é¡»ä½¿ç”¨ `fig = plt.figure()` æˆ– `fig = plt.subplots()`ã€‚
    3. ä¸è¦ä½¿ç”¨ `plt.show()`ã€‚
    4. è¯·ç¡®ä¿ä»£ç æœ€åè°ƒç”¨ `fig.tight_layout()`ã€‚
    5. æ‰€æœ‰ç»˜å›¾ä»£ç ä¸­ï¼Œåæ ‡è½´æ ‡ç­¾ï¼ˆxlabelã€ylabelï¼‰ã€æ ‡é¢˜ï¼ˆtitleï¼‰ã€å›¾ä¾‹ï¼ˆlegendï¼‰ç­‰æ–‡æœ¬å†…å®¹ï¼Œå¿…é¡»ä½¿ç”¨è‹±æ–‡æè¿°ã€‚

    ç¤ºä¾‹ä»£ç ï¼š
    fig = plt.figure(figsize=(10,6))
    plt.plot([1,2,3], [4,5,6])
    fig.tight_layout()
    """
    # print("æ­£åœ¨è°ƒç”¨fig_interå·¥å…·è¿è¡ŒPythonä»£ç ...")

    current_backend = matplotlib.get_backend()
    matplotlib.use('Agg')

    local_vars = {"plt": plt, "pd": pd, "sns": sns}
    
    # âœ… è®¾ç½®å›¾åƒä¿å­˜è·¯å¾„ï¼ˆåŠ¨æ€è·å–å½“å‰é¡¹ç›®ç›®å½•ï¼‰
    current_dir = os.path.dirname(os.path.abspath(__file__))  # è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•
    images_dir = os.path.join(current_dir, "images")
    os.makedirs(images_dir, exist_ok=True)  # âœ… è‡ªåŠ¨åˆ›å»º images æ–‡ä»¶å¤¹ï¼ˆå¦‚ä¸å­˜åœ¨ï¼‰
    try:
        g = globals()
        exec(py_code, g, local_vars)
        g.update(local_vars)

        fig = local_vars.get(fname, None)
        if fig:
            image_filename = f"{fname}.png"
            abs_path = os.path.join(images_dir, image_filename)  # âœ… ç»å¯¹è·¯å¾„
            rel_path = os.path.join("images", image_filename)    # âœ… è¿”å›ç›¸å¯¹è·¯å¾„ï¼ˆç»™å‰ç«¯ç”¨ï¼‰

            fig.savefig(abs_path, bbox_inches='tight')
            return f"âœ… å›¾ç‰‡å·²ä¿å­˜ï¼Œè·¯å¾„ä¸º: {rel_path}"
        else:
            return "âš ï¸ å›¾åƒå¯¹è±¡æœªæ‰¾åˆ°ï¼Œè¯·ç¡®è®¤å˜é‡åæ­£ç¡®å¹¶ä¸º matplotlib å›¾å¯¹è±¡ã€‚"
    except Exception as e:
        return f"âŒ æ‰§è¡Œå¤±è´¥ï¼š{e}"
    finally:
        plt.close('all')
        matplotlib.use(current_backend)


# âœ… åˆ›å»ºå·¥å…·åˆ—è¡¨
tools = [
    file_operations,
    get_system_info,
    execute_command,
    datetime_operations,
    csv_operations,
    python_inter, 
    fig_inter, 
]

# âœ… åˆ›å»ºæ¨¡å‹
model = ChatDeepSeek(model="deepseek-chat")

# âœ… åˆ›å»ºå›¾ ï¼ˆAgentï¼‰
graph = create_react_agent(model=model, tools=tools, prompt=prompt)
